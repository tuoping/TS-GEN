{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgen.parsing import parse_train_args\n",
    "\n",
    "from mdgen.logger import get_logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "import torch, os\n",
    "from mdgen.dataset import EquivariantTransformerDataset_MaterialProject\n",
    "\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "# args = parse_train_args()\n",
    "    \n",
    "\n",
    "trainset = EquivariantTransformerDataset_MaterialProject(\"data/MP_LixSiy_sims\", 6, num_species=94, localmask=False, sim_condition=False, stage=\"save\", save_dir=\"data/MP_LixSiy_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_data = len(trainset)\n",
    "for i in range(num_data):\n",
    "    len_traj = trainset[i]\n",
    "    print(i, num_data, len_traj)\n",
    "    # print(sample_traj.keys())\n",
    "    # print(sample_traj[\"x\"].shape)\n",
    "    # print((sample_traj[\"cell\"]).shape)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "sample_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgen.parsing import parse_train_args\n",
    "\n",
    "from mdgen.logger import get_logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "import torch, os, wandb\n",
    "from mdgen.dataset import MDGenDataset\n",
    "from mdgen.wrapper import NewMDGenWrapper\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "# args = parse_train_args()\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(ckpt=None, validate=False, num_workers=4, epochs=10000, overfit=False, overfit_peptide=None, overfit_frame=False, train_batches=None, val_batches=None, val_repeat=25, inference_batches=0, batch_size=128, val_freq=None, val_epoch_freq=1, no_validate=False, designability_freq=1, print_freq=100, ckpt_freq=40, wandb=False, run_name='default', accumulate_grad=1, grad_clip=1.0, check_grad=False, grad_checkpointing=False, adamW=False, ema=False, ema_decay=0.999, lr=0.0001, precision='32-true', train_split='splits/4AA_train.csv', val_split='splits/4AA_val.csv', data_dir='data/4AA_data/', num_frames=100, crop=4, suffix=\"\", atlas=False, copy_frames=False, no_pad=False, short_md=False, design_key_frames=False, no_aa_emb=False, no_torsion=False, no_design_torsion=False, supervise_no_torsions=False, supervise_all_torsions=False, no_offsets=False, no_frames=False, hyena=False, no_rope=False, dropout=0.0, scale_factor=1.0, interleave_ipa=False, prepend_ipa=True, oracle=False, num_layers=5, embed_dim=64, mha_heads=16, ipa_heads=4, ipa_head_dim=32, ipa_qk=8, ipa_v=8, time_multiplier=100.0, abs_pos_emb=True, abs_time_emb=False, path_type='GVP', prediction='velocity', sampling_method='dopri5', alpha_max=8, discrete_loss_weight=0.5, dirichlet_flow_temp=1.0, allow_nan_cfactor=False, tps_condition=True, design=False, design_from_traj=False, sim_condition=False, inpainting=False, dynamic_mpnn=False, mpnn=False, frame_interval=None, cond_interval=None)\n",
    "\n",
    "args.sim_condition=True\n",
    "args.data_dir=\"data/CrCoNi_data\" \n",
    "args.num_frames=1\n",
    "\n",
    "args.crop=4 \n",
    "args.ckpt_freq = 40 \n",
    "args.val_repeat = 25 \n",
    "args.epochs = 10\n",
    "args.num_species = 5\n",
    "\n",
    "args.edge_dim = 4\n",
    "args.num_convs = 5\n",
    "args.num_heads = 4\n",
    "args.ff_dim = 16\n",
    "\n",
    "args.cutoff= 4\n",
    "args.localmask = False\n",
    "args.path_type = \"Linear\"\n",
    "args.batch_size = batch_size\n",
    "# args.prediction='score'\n",
    "# args.sampling_method = \"Euler\"\n",
    "\n",
    "args.design = False\n",
    "args.potential_model = True\n",
    "\n",
    "os.environ[\"MODEL_DIR\"] = os.path.join(\"workdir\", args.run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgen.equivariant_wrapper import EquivariantMDGenWrapper\n",
    "model = EquivariantMDGenWrapper(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model.iter_step += 1\n",
    "model.stage = \"train\"\n",
    "start1 = time.time()\n",
    "prep = model.prep_batch(sample_batch)\n",
    "start = time.time()\n",
    "print(\"prep time:\", start-start1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep.keys())\n",
    "print(prep[\"model_kwargs\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep[\"model_kwargs\"][\"conditions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep[\"model_kwargs\"][\"conditions\"][\"x\"].shape)\n",
    "print(prep[\"model_kwargs\"][\"conditions\"][\"mask\"].shape)\n",
    "raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test graph algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgen.model.utils.data_utils import (\n",
    "    frac_to_cart_coords_with_lattice,\n",
    "    get_pbc_distances,\n",
    "    lattice_params_to_matrix_torch,\n",
    "    radius_graph_pbc,\n",
    ")\n",
    "from mdgen.model.gemnet.utils import (\n",
    "    repeat_blocks,\n",
    ")\n",
    "otf_graph = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# edge_index, to_jimages, num_bonds = radius_graph_pbc(\n",
    "#     cart_coords=prep['latents'].view(-1, 3),\n",
    "#     lattice=prep['model_kwargs']['cell'].view(-1, 3, 3),\n",
    "#     num_atoms=prep['model_kwargs']['num_atoms'].view(-1),\n",
    "#     radius=model.model.cutoff,\n",
    "#     max_num_neighbors_threshold=50,\n",
    "#     max_cell_images_per_dim=5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x0, x1 = model.transport.sample(prep['latents'])\n",
    "t, xt, ut = model.transport.path_sampler.plan(t, x0, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prep['latents'][0].unsqueeze(0).shape)\n",
    "# v_latents = prep['latents'][0].unsqueeze(0).expand(batch_size,-1,-1,-1)\n",
    "# print(v_latents.shape)\n",
    "# print(prep['model_kwargs']['cell'][0].unsqueeze(0).shape)\n",
    "# v_cell = prep['model_kwargs']['cell'][0].unsqueeze(0).expand(batch_size,-1,-1,-1)\n",
    "# print(v_cell.shape)\n",
    "# print(prep['model_kwargs']['num_atoms'][0].unsqueeze(0).shape)\n",
    "# v_num_atoms = prep['model_kwargs']['num_atoms'][0].unsqueeze(0).expand(batch_size,-1)\n",
    "# print(v_num_atoms.shape)\n",
    "# print(prep['species'][0].unsqueeze(0).shape)\n",
    "# v_species = prep['species'][0].unsqueeze(0).expand(batch_size,-1,-1,-1)\n",
    "# print(v_species.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# edge_index, to_jimages, num_bonds = radius_graph_pbc(\n",
    "#     cart_coords=v_latents.reshape(-1, 3),\n",
    "#     lattice=v_cell.view(-1, 3, 3),\n",
    "#     num_atoms=v_num_atoms.view(-1),\n",
    "#     radius=model.model.cutoff,\n",
    "#     max_num_neighbors_threshold=50,\n",
    "#     max_cell_images_per_dim=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = prep[\"model_kwargs\"][\"conditions\"]\n",
    "edge_index_cond, to_jimages_cond, num_bonds_cond = radius_graph_pbc(\n",
    "    cart_coords=conditions[\"x\"].view(-1, 3),\n",
    "    lattice=conditions[\"cell\"].view(-1, 3, 3),\n",
    "    num_atoms=conditions[\"num_atoms\"].view(-1),\n",
    "    radius=model.model.cutoff,\n",
    "    max_num_neighbors_threshold=model.model.max_num_neighbors_threshold,\n",
    "    max_cell_images_per_dim=model.model.max_cell_images_per_dim,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = get_pbc_distances(\n",
    "#     prep['latents'].view(-1, 3),\n",
    "#     edge_index,\n",
    "#     prep['model_kwargs']['cell'].view(-1, 3, 3),\n",
    "#     to_jimages,\n",
    "#     prep['model_kwargs']['num_atoms'].view(-1),\n",
    "#     num_bonds,\n",
    "#     coord_is_cart=True,\n",
    "#     return_offsets=True,\n",
    "#     return_distance_vec=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = get_pbc_distances(\n",
    "#     v_latents.reshape(-1, 3),\n",
    "#     edge_index,\n",
    "#     v_cell.view(-1, 3, 3),\n",
    "#     to_jimages,\n",
    "#     v_num_atoms.view(-1),\n",
    "#     num_bonds,\n",
    "#     coord_is_cart=True,\n",
    "#     return_offsets=True,\n",
    "#     return_distance_vec=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cond = get_pbc_distances(\n",
    "    conditions[\"x\"].view(-1, 3),\n",
    "    edge_index_cond,\n",
    "    conditions[\"cell\"].view(-1, 3, 3),\n",
    "    to_jimages_cond,\n",
    "    conditions[\"num_atoms\"].view(-1),\n",
    "    num_bonds_cond,\n",
    "    coord_is_cart=True,\n",
    "    return_offsets=True,\n",
    "    return_distance_vec=True,\n",
    ")\n",
    "out_cond[\"species\"] = conditions[\"species\"]\n",
    "out_cond[\"mask\"] = conditions[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index = out[\"edge_index\"]\n",
    "# edge_len = out[\"distances\"]\n",
    "# edge_vec = out[\"distance_vec\"]\n",
    "# edge_attr = torch.hstack([edge_vec, edge_len.view(-1, 1)])\n",
    "# B,T,L,_ = v_species.shape\n",
    "# t = t.unsqueeze(-1).unsqueeze(1).expand(-1,T,-1).unsqueeze(2).expand(-1,-1,L,-1)\n",
    "# h,v,_edge_attr = model.model.encoder(v_species.reshape(-1,5), edge_index, edge_attr, edge_vec, t.reshape(-1,1), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if out_cond is not None:\n",
    "    edge_index_cond = out_cond[\"edge_index\"]\n",
    "    edge_len_cond = out_cond[\"distances\"]\n",
    "    edge_vec_cond = out_cond[\"distance_vec\"]\n",
    "    edge_attr_cond = torch.hstack([edge_vec_cond, edge_len_cond.view(-1, 1)])\n",
    "    species_cond = out_cond[\"species\"]\n",
    "\n",
    "    h_cond, v_cond, edge_attr_cond = model.model.encoder(\n",
    "        species_cond.view(-1,5), \n",
    "        edge_index_cond, edge_attr_cond, edge_vec_cond, \n",
    "        torch.zeros([*species_cond.shape[:-1],1], device=species_cond.device).reshape(-1,1))\n",
    "    print(h_cond.shape)\n",
    "    print(torch.where(out_cond[\"mask\"].reshape(-1,1)))\n",
    "    # for i in range()\n",
    "    for i in range(h_cond.shape[0]):\n",
    "        print(i, (model.model.cond_to_emb(h_cond)*(out_cond[\"mask\"].reshape(-1,1)))[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = out[\"edge_index\"]\n",
    "edge_len = out[\"distances\"]\n",
    "edge_vector = out[\"distance_vec\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# !!! need to keep track of index exchanges and take into consideration when inferencing to use this\n",
    "edge_index, cell_offsets, neighbors, edge_len, edge_vec = reorder_symmetric_edges(\n",
    "        edge_index,\n",
    "        to_jimages,\n",
    "        num_bonds,\n",
    "        out[\"distances\"],\n",
    "        out[\"distance_vec\"],\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test equivariant_latent_model for energy and forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep.keys())\n",
    "t = torch.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = model.model(prep[\"latents\"], t, **prep[\"model_kwargs\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(energy)\n",
    "print(energy.sum(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_energy = (energy - prep[\"E\"])**2\n",
    "print(loss_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test equivariant_latent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x0, x1 = model.transport.sample(prep['latents'])\n",
    "# t, xt, ut = model.transport.path_sampler.plan(t, x0, x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.transport.path_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep[\"model_kwargs\"][\"conditions\"]['mask'].reshape(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.model.mask_to_emb(prep[\"model_kwargs\"][\"conditions\"]['mask'].reshape(-1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.model(prep['latents'], t, **prep['model_kwargs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = model.transport.training_losses(\n",
    "    model=model.model,\n",
    "    x1=prep['latents'],\n",
    "    aatype1=prep['species'],\n",
    "    mask=prep['loss_mask'],\n",
    "    model_kwargs=prep['model_kwargs']\n",
    ")\n",
    "# loss = out_dict[\"loss\"].mean()\n",
    "print(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep['model_kwargs'][\"conditions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.model.parameters(), lr=0.001)\n",
    "loss_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.transport.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    Step = 0\n",
    "    # for batch in train_loader:\n",
    "    #     # Forward pass\n",
    "    #     batch_ = {key: value.to(device) if isinstance(value, torch.Tensor) else value \n",
    "    #             for key, value in batch.items()}\n",
    "    #     prep = model.prep_batch(batch_)\n",
    "    # out_dict = model.transport.training_losses(\n",
    "    #     model=model.model,\n",
    "    #     x1=prep['latents'],\n",
    "    #     aatype1=prep['species'],\n",
    "    #     mask=prep['loss_mask'],\n",
    "    #     model_kwargs=prep['model_kwargs']\n",
    "    # )\n",
    "    # loss = out_dict[\"loss\"].mean()\n",
    "    t = torch.ones(batch_size)\n",
    "    energy = model.model(prep[\"latents\"], t, **prep[\"model_kwargs\"] )\n",
    "    loss = ((energy - prep[\"E\"])**2).mean()\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    # print(\"Starting backward\")\n",
    "    loss.backward()\n",
    "    # print(\"Done\")\n",
    "    optimizer.step()\n",
    "    Step += 1\n",
    "    loss_epochs.append(loss.item())\n",
    "    # print(f'Epoch [{epoch+1}/{num_epochs}], Step [{Step}], Loss: {loss.item():.4f}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,3.5))\n",
    "plt.plot(loss_epochs)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x0, x1 = model.transport.sample(prep['latents'])\n",
    "t, xt, ut = model.transport.path_sampler.plan(t, x0, x1)\n",
    "out_dict = model.transport.training_losses(\n",
    "    model=model.model,\n",
    "    x1=prep['latents'],\n",
    "    aatype1=prep['species'],\n",
    "    mask=prep['loss_mask'],\n",
    "    model_kwargs=prep['model_kwargs']\n",
    ")\n",
    "loss_last = out_dict[\"loss_continuous\"][torch.where(prep['loss_mask'].squeeze(-1)!=0)].detach().mean(dim=1)\n",
    "loss_fkl_last = out_dict[\"loss_fisherreg\"]\n",
    "print(loss_last)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,3.5))\n",
    "plt.scatter(t.detach().cpu().numpy(), loss_last.detach().cpu().numpy())\n",
    "plt.scatter(t.detach().cpu().numpy(), loss_fkl_last.detach().cpu().numpy())\n",
    "plt.xlabel(\"Diffusion time\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3.5))\n",
    "plt.scatter(t.detach().cpu().numpy(), loss_last.detach().cpu().numpy())\n",
    "plt.xlabel(\"Diffusion time\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odefed_mdgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
