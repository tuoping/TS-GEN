{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4409aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transition1x import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a716ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "dataloader = Dataloader(\"data/transition1x.h5\", datasplit=\"test\", only_final=True)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from ase import Atoms\n",
    "import ase.io\n",
    "atom_encoder = OneHotEncoder(sparse_output=False)\n",
    "atom_encoder.fit(np.array([1, 6, 7, 8]).reshape(-1,1))\n",
    "idx = 0\n",
    "dataset = []\n",
    "for molecule in dataloader:\n",
    "    z_r = atom_encoder.transform(np.array(molecule[\"reactant\"][\"atomic_numbers\"]).reshape(-1, 1))\n",
    "    padded_z_r = np.zeros((len(molecule[\"reactant\"][\"atomic_numbers\"]), 5))\n",
    "    padded_z_r[:,:z_r.shape[1]] = z_r\n",
    "\n",
    "    z_p = atom_encoder.transform(np.array(molecule[\"product\"][\"atomic_numbers\"]).reshape(-1, 1))\n",
    "    padded_z_p = np.zeros((len(molecule[\"product\"][\"atomic_numbers\"]), 5))\n",
    "    padded_z_p[:,:z_p.shape[1]] = z_p\n",
    "\n",
    "    z_t = atom_encoder.transform(np.array(molecule[\"transition_state\"][\"atomic_numbers\"]).reshape(-1, 1))\n",
    "    padded_z_t = np.zeros((len(molecule[\"transition_state\"][\"atomic_numbers\"]), 5))\n",
    "    padded_z_t[:,:z_t.shape[1]] = z_t\n",
    "    data = Data(\n",
    "        rxn = molecule['rxn'],\n",
    "        E_transition_state = torch.tensor(molecule[\"transition_state\"][\"wB97x_6-31G(d).atomization_energy\"], dtype=torch.float32),\n",
    "        E_reactant = torch.tensor(molecule[\"reactant\"][\"wB97x_6-31G(d).atomization_energy\"], dtype=torch.float32),\n",
    "        E_product = torch.tensor(molecule[\"product\"][\"wB97x_6-31G(d).atomization_energy\"], dtype=torch.float32),\n",
    "\n",
    "        pos_transition_state = torch.tensor(molecule[\"transition_state\"][\"positions\"], dtype=torch.float32),\n",
    "        formula_transition_state = molecule[\"transition_state\"][\"formula\"],\n",
    "        z_transition_state = torch.tensor(padded_z_t, dtype=torch.float32),\n",
    "\n",
    "        pos_reactant = torch.tensor(molecule[\"reactant\"][\"positions\"], dtype=torch.float32),\n",
    "        formula_reactant = molecule[\"reactant\"][\"formula\"],\n",
    "        z_reactant = torch.tensor(padded_z_r, dtype=torch.float32),\n",
    "        \n",
    "        pos_product = torch.tensor(molecule[\"product\"][\"positions\"], dtype=torch.float32),\n",
    "        formula_product = molecule[\"product\"][\"formula\"],\n",
    "        z_product = torch.tensor(padded_z_p, dtype=torch.float32),\n",
    "        \n",
    "    )\n",
    "    atoms = Atoms(molecule[\"reactant\"][\"formula\"], positions=molecule[\"reactant\"][\"positions\"])\n",
    "    ase.io.write(f\"{molecule['rxn']}-{idx}.xyz\", atoms, format=\"xyz\", append=True)\n",
    "    atoms = Atoms(molecule[\"transition_state\"][\"formula\"], positions=molecule[\"transition_state\"][\"positions\"])\n",
    "    ase.io.write(f\"{molecule['rxn']}-{idx}.xyz\", atoms, format=\"xyz\", append=True)\n",
    "    atoms = Atoms(molecule[\"product\"][\"formula\"], positions=molecule[\"product\"][\"positions\"])\n",
    "    ase.io.write(f\"{molecule['rxn']}-{idx}.xyz\", atoms, format=\"xyz\", append=True)\n",
    "    idx += 1\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d38f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, \"data/test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mdgen.dataset import EquivariantTransformerDataset_Transition1x\n",
    "data_dir = \"data\"\n",
    "dataset = EquivariantTransformerDataset_Transition1x(data_dirname=data_dir, sim_condition=False, tps_condition=True, num_species=5, stage=\"test\")\n",
    "\n",
    "tps_masked_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    tps_masked_dataset.append(dataset[i])\n",
    "\n",
    "torch.save(tps_masked_dataset, f\"{data_dir}/tps_masked_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_reactant = [data.E_reactant for data in dataset]\n",
    "E_product = [data.E_product for data in dataset]\n",
    "E_transition_state = [data.E_transition_state for data in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3621763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(E_reactant)\n",
    "_ = plt.hist(E_product)\n",
    "_ = plt.hist(E_transition_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = plt.hist(np.array(E_transition_state) - np.array(E_reactant))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odefed_mdgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
